{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMw+MmsmnHR7BN6ZDGSW3mV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parvvaresh/Neural-Networks/blob/main/Neural-Networks/Neural_Networks_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJr8oc6N6ymK"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.datasets import make_classification"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are a couple of parameters that you may find yourself needing to change in the MLPClassifier.\n",
        "\n",
        "You can configure the number of hidden layers and how many nodes in each layer. The default MLPClassifier will have a single hidden layer of 100 nodes. This often works really well, but we can experiment with different values. This will create an MLPCLassifier with two hidden layers, one of 100 nodes and one of 50 nodes.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "model = MLPClassifier(max_iter = 1000, hidden_layer_size = (100, 50))\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "yGnCDfDN7yUt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We saw max_iter in the previous part. This is the number of iterations. In general, the more data you have, the fewer iterations you need to converge. If the value is too large, it will take too long to run the code. If the value is too small, the neural network will not converge on the optimal solution.\n",
        "\n",
        "We also sometimes need to change alpha, which is the step size. This is how much the neural network changes the coefficients at each iteration. If the value is too small, you may never converge on the optimal solution. If the value is too large, you may miss the optimal solution. Initially you can leave this at the default. The default value of alpha is 0.0001. Note that decreasing alpha often requires an increase in max_iter.\n",
        "\n",
        "Sometimes you will want to change the solver. This is what algorithm is used to find the optimal solution. All the solvers will work, but you may find for your dataset that a different solver finds the optimal solution faster. The options for solver are 'lbfgs', 'sgd' and 'adam'.\n",
        "\n",
        "Run this code in the playground and try changing the parameters for the MLPClassifier. The code uses a random_state to ensure that every time you run the code with the same parameters you will get the same output."
      ],
      "metadata": {
        "id": "NIyqI6bC8wKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create data sets\n",
        "\n",
        "x, y = make_classification(random_state = 3, n_features = 2, n_informative = 2, n_redundant = 0)\n",
        "\n",
        "\n",
        "print(f\"x rows : {x.shape[0]} and x columns : {x.shape[1]}\")\n",
        "print(f\"y rows : {y.shape[0]} and y columns : 1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQr_KL2I8zpS",
        "outputId": "5a50e7ad-be56-4eea-de4a-a306f5423946"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x rows : 100 and x columns : 2\n",
            "y rows : 100 and y columns : 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#make test and train\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 3)"
      ],
      "metadata": {
        "id": "-M8PKR3i9QeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#make and fit model \n",
        "\n",
        "model = MLPClassifier(max_iter = 1000, alpha = 0.0001, hidden_layer_sizes = (100, 50), solver = \"adam\", random_state = 3)\n",
        "\n",
        "model.fit(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPzawbsP9hHc",
        "outputId": "33c8575f-f174-4f11-a841-618e30b6c581"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=3)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#score\n",
        "\n",
        "\n",
        "print(f\"score of this model is : {model.score(x_test, y_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3krytAyQ-WbN",
        "outputId": "82f30691-f166-49da-8cb9-5f0de3b64f67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score of this model is : 0.76\n"
          ]
        }
      ]
    }
  ]
}